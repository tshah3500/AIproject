{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarun\\AppData\\Local\\Temp\\ipykernel_30996\\1790986702.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataset['review_rating'] = dataset['review_rating'].apply(match_score).astype(float)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\\n  Yea..pre-ordered on 28 July, got it on 4 A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\\n  Got it delivered yesterday , used for abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\\n  An amazing phone!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\\n  Brilliant..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>\\n  I was skeptical about changing from One pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30607</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n  Quality of phone is great but from my pers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30608</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n  Not recommend\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30609</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n  Redmi and Amazon is engaged in a worst mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30610</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n  I am facing display retention problem, aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30611</th>\n",
       "      <td>2.0</td>\n",
       "      <td>\\n  Front camera quality is worse as compare t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30612 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_rating                                        review_text\n",
       "0                5.0  \\n  Yea..pre-ordered on 28 July, got it on 4 A...\n",
       "1                5.0  \\n  Got it delivered yesterday , used for abou...\n",
       "2                5.0                              \\n  An amazing phone!\n",
       "3                5.0                                    \\n  Brilliant..\n",
       "4                5.0  \\n  I was skeptical about changing from One pl...\n",
       "...              ...                                                ...\n",
       "30607            2.0  \\n  Quality of phone is great but from my pers...\n",
       "30608            2.0                                \\n  Not recommend\\n\n",
       "30609            2.0  \\n  Redmi and Amazon is engaged in a worst mar...\n",
       "30610            2.0  \\n  I am facing display retention problem, aft...\n",
       "30611            2.0  \\n  Front camera quality is worse as compare t...\n",
       "\n",
       "[30612 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preproccessing \n",
    "def match_score(val):\n",
    "    return re.findall('[0-9].0', val)[0]\n",
    "\n",
    "df = pd.read_json('amazon_one_plus_reviews.json')\n",
    "dataset = df[['review_rating', 'review_text']]\n",
    "dataset['review_rating'] = dataset['review_rating'].apply(match_score).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    13967\n",
       "4.0     8537\n",
       "3.0     4172\n",
       "1.0     2088\n",
       "2.0     1848\n",
       "Name: review_rating, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['review_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard BoW\n",
    "\"\"\"\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "cv = CountVectorizer(stop_words='english', ngram_range = (1,1), tokenizer = token.tokenize)\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "\"\"\"\n",
    "#TFIDF\n",
    "cv =TfidfVectorizer(max_df=0.90, min_df=2,max_features=1000,stop_words='english')\n",
    "text_counts=cv.fit_transform(dataset['review_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Accuracy: 0.5093427414085979\n",
      "Max_df: 0.5 | Min_df: 0.01\n",
      "Highest Distance Score: 0.7429880513002021\n",
      "Max_df: 0.5 | Min_df: 0.01\n"
     ]
    }
   ],
   "source": [
    "def score(predictions, test):\n",
    "    correct = 0 \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == test[test.index[i]]:\n",
    "            correct += 1\n",
    "    return(correct/len(predictions)) \n",
    "\n",
    "def distance_function(predictions, test):\n",
    "    total_distance = 0\n",
    "    total = 0\n",
    "    for i in range(len(predictions)):\n",
    "        distance = (predictions[i]  - test[test.index[i]])**2\n",
    "        total_distance += distance\n",
    "        total += 25\n",
    "    return(1-(math.sqrt(total_distance/total)))\n",
    "\n",
    "highest_accuracy = 0\n",
    "highest_distance = 0\n",
    "acc_vals = [0,0]\n",
    "dis_vals = [0,0]\n",
    "for i in [.5, .6, .7, .8, .9]:\n",
    "    for j in [.01, .02, .03, .04, .05, .06, .07, .08, .09, .1]:\n",
    "        cv =TfidfVectorizer(max_df=i, min_df=j,max_features=1000,stop_words='english')\n",
    "        text_counts=cv.fit_transform(dataset['review_text'])\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "        model = MultinomialNB()\n",
    "        model.fit(X_train, Y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = score(predictions, Y_test)\n",
    "        distance = distance_function(predictions, Y_test)\n",
    "        if distance > highest_distance:\n",
    "            highest_distance = distance\n",
    "            dis_vals = [i,j]\n",
    "        if accuracy > highest_accuracy:\n",
    "            highest_accuracy = accuracy\n",
    "            acc_vals = [i,j]\n",
    "        \"\"\"\n",
    "        print(\"\\nMax_df: \" + str(i) + \" | Min_df: \" + str(j))\n",
    "        print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "        print(\"Distance: \" + str(distance*100))\n",
    "        print(\"\\n\")\n",
    "        \"\"\"\n",
    "print(\"Highest Accuracy: \" + str(highest_accuracy))\n",
    "print(\"Max_df: \" + str(acc_vals[0]) + \" | Min_df: \" + str(acc_vals[1]))\n",
    "print(\"Highest Distance Score: \" + str(highest_distance))\n",
    "print(\"Max_df: \" + str(dis_vals[0]) + \" | Min_df: \" + str(dis_vals[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cv =TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (1,3), stop_words='english')\n",
    "text_counts=cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Bag of Words Classifer-------------\n",
      "Accuracy: 52.593754083365994\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def score(predictions, test):\n",
    "    correct = 0 \n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == test[test.index[i]]:\n",
    "            correct += 1\n",
    "    return(correct/len(predictions)) \n",
    "\n",
    "def distance_function(predictions, test):\n",
    "    total_distance = 0\n",
    "    total = 0\n",
    "    for i in range(len(predictions)):\n",
    "        distance = (predictions[i]  - test[test.index[i]])**2\n",
    "        total_distance += distance\n",
    "        total += 25\n",
    "    return(1-(math.sqrt(total_distance/total)))\n",
    "\n",
    "\n",
    "basic_model = MultinomialNB()\n",
    "basic_model.fit(X_train, Y_train)\n",
    "predictions = basic_model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "print(\"-------------Bag of Words Classifer-------------\")\n",
    "print(\"Accuracy: \" + str(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Only Single-------------\n",
      "\n",
      "Accuracy: 51.91428198092252\n",
      "Distance: 76.55781303669876\n",
      "\n",
      "\n",
      "-------------Single & Bigram-------------\n",
      "\n",
      "Accuracy: 52.52842022736181\n",
      "Distance: 77.17461278927028\n",
      "\n",
      "\n",
      "-------------Only Bigram-------------\n",
      "\n",
      "Accuracy: 49.37932836796028\n",
      "Distance: 73.93531952480753\n",
      "\n",
      "\n",
      "-------------Single, Bigram, & Trigram-------------\n",
      "\n",
      "Accuracy: 52.593754083365994\n",
      "Distance: 77.1929390766173\n",
      "\n",
      "\n",
      "-------------Bigram & Trigram-------------\n",
      "\n",
      "Accuracy: 49.22252711355024\n",
      "Distance: 73.78435775955155\n",
      "\n",
      "\n",
      "-------------Only Trigram-------------\n",
      "\n",
      "Accuracy: 46.38703776296877\n",
      "Distance: 69.96539301703895\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------Only Single-------------\")\n",
    "cv = TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (1,1), stop_words='english')\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "distance = distance_function(predictions, Y_test)\n",
    "print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "print(\"Distance: \" + str(distance*100))\n",
    "print(\"\\n\")\n",
    "print(\"-------------Single & Bigram-------------\")\n",
    "cv = TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (1,2), stop_words='english')\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "distance = distance_function(predictions, Y_test)\n",
    "print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "print(\"Distance: \" + str(distance*100))\n",
    "print(\"\\n\")\n",
    "print(\"-------------Only Bigram-------------\")\n",
    "cv = TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (2,2), stop_words='english')\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "distance = distance_function(predictions, Y_test)\n",
    "print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "print(\"Distance: \" + str(distance*100))\n",
    "print(\"\\n\")\n",
    "print(\"-------------Single, Bigram, & Trigram-------------\")\n",
    "cv = TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (1,3), stop_words='english')\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "distance = distance_function(predictions, Y_test)\n",
    "print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "print(\"Distance: \" + str(distance*100))\n",
    "print(\"\\n\")\n",
    "print(\"-------------Bigram & Trigram-------------\")\n",
    "cv = TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (2,3), stop_words='english')\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "distance = distance_function(predictions, Y_test)\n",
    "print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "print(\"Distance: \" + str(distance*100))\n",
    "print(\"\\n\")\n",
    "print(\"-------------Only Trigram-------------\")\n",
    "cv = TfidfVectorizer(max_df=0.5, min_df=0,max_features=1000, ngram_range = (3,3), stop_words='english')\n",
    "text_counts = cv.fit_transform(dataset['review_text'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(text_counts, dataset['review_rating'], test_size = .25, random_state=5)\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = score(predictions, Y_test)\n",
    "distance = distance_function(predictions, Y_test)\n",
    "print(\"\\nAccuracy: \" + str(accuracy*100))\n",
    "print(\"Distance: \" + str(distance*100))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 4., 4., ..., 4., 4., 5.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([25605,  5660,  8949, 25536,  8441, 22645, 18013,   868,  7155,\n",
       "             7462,\n",
       "            ...\n",
       "              611, 10064,  1026, 21386,  2457,  2519, 10211,  8977, 15067,\n",
       "            12448],\n",
       "           dtype='int64', length=7653)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
